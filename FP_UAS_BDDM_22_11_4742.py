# -*- coding: utf-8 -*-
"""FP_BDDM_22.11.4742

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rbflyPuqZk6DFu9whGcKyekctQLRwNxx

Link Dataset : https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data

Nama : Dimas Ramadhan Alfinsyah

NIM  : 22.11.4742

# Import library
"""

# Commented out IPython magic to ensure Python compatibility.
# Import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Set matplotlib untuk menampilkan plot di notebook
# %matplotlib inline

# Optional: Set tema seaborn (opsional)
sns.set_theme()

"""# Pengumpulan Data"""

# Load dataset
dataset_path = '/content/heart.csv'
data = pd.read_csv(dataset_path)

# Tampilkan 10 baris pertama
print("10 Baris Pertama Dataset:")
print(data.head(10))

# Ukuran data
print("\nUkuran Dataset:", data.shape)

# Informasi data
print("\nInformasi Dataset:")
data.info()

"""# Data Preprocessing"""

# Handling missing values
print("\nJumlah Missing Values Sebelum Penanganan:")
print(data.isnull().sum())
data.fillna(data.median(numeric_only=True), inplace=True)  # Mengisi nilai numerik yang hilang dengan median

# Jumlah duplikasi
duplicates = data.duplicated().sum()
print("\nJumlah Duplikasi:", duplicates)
data.drop_duplicates(inplace=True)

# Melakukan encoding data
data['Sex'] = data['Sex'].map({'M': 0, 'F': 1})
data['ExerciseAngina'] = data['ExerciseAngina'].map({'N': 0, 'Y': 1})
data['ST_Slope'] = data['ST_Slope'].map({'Flat': 0, 'Up': 1})
data['ChestPainType'] = data['ChestPainType'].map({'TA': 0, 'ATA': 1,'NAP': 2, 'ASY': 3 })
data['RestingECG'] = data['RestingECG'].map({'Normal': 0, 'ST': 1})

# Tampilkan 10 baris pertama setelah perubahan
print("\n10 Baris Pertama Setelah Perubahan:")
print(data.head(10))

# Informasi data setelah konversi
print("\nInformasi Dataset Setelah Konversi:")
data.info()

"""# Exploratory Data Analysis"""

# Visualisasi distribusi fitur numerik
numerical_cols = data.select_dtypes(include=[np.number]).columns
print("\nFitur Numerik:", list(numerical_cols))

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(len(numerical_cols)//3 + 1, 3, i + 1)
    sns.histplot(data[col], kde=True, bins=30, color='blue')
    plt.title(f'Distribusi {col}')
plt.tight_layout()
plt.show()

# Analisis Korelasi
plt.figure(figsize=(10, 8))
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matriks Korelasi')
plt.show()

"""# Seleksi Fitur"""

# Pisahkan fitur (X) dan target (y)
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Bagi dataset menjadi data latih dan data uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

# Create an imputer to fill NaN values with the mean
imputer = SimpleImputer(strategy='mean')

# Fit the imputer on the training data and transform both train and test data
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

"""# Modeling"""

# Inisialisasi model Gradient Boosting Machines (GBM)
gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Melatih model pada data pelatihan
gbm_model.fit(X_train, y_train)

# Melakukan prediksi pada data uji
y_pred = gbm_model.predict(X_test)

# Mengukur akurasi model
accuracy_gbm = accuracy_score(y_test, y_pred)

# Confusion matrix
cmr = confusion_matrix(y_test, y_pred)

labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
cm_labels = [f"{label}\n{value}" for label, value in zip(labels, cmr.flatten())]
cm_labels = np.array(cm_labels).reshape(2, 2)

class_report = classification_report(y_test, y_pred)

print('\nConfusion Matrix:')
print(cmr)

# Plot confusion matrix
sns.heatmap(cmr / np.sum(cmr), annot=cm_labels, fmt='', cmap='coolwarm', annot_kws={'size': 12})
plt.title('Confusion Matrix with Percentages')
plt.show()

"""# Evaluasi Model"""

print("Accuracy (GBM):", accuracy_gbm)

# Menampilkan informasi klasifikasi
print(class_report)